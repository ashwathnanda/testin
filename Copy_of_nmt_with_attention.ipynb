{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of nmt_with_attention.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashwathnanda/testin/blob/master/Copy_of_nmt_with_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "# Neural Machine Translation with Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tnxXKDjq3jEL",
        "outputId": "06248eac-c2a1-40bc-f9a1-773756617bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install tensorflow-gpu==2.0.0-alpha0\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
            "\u001b[K     |████████████████████████████████| 332.1MB 58kB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow-gpu==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 34.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.16.3)\n",
            "Collecting google-pasta>=0.1.2 (from tensorflow-gpu==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/68/a14620bfb042691f532dcde8576ff82ee82e4c003cdc0a3dbee5f289cee6/google_pasta-0.1.6-py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 27.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.7)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.7.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.4)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow-gpu==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 37.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (41.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.15.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.1)\n",
            "Installing collected packages: tf-estimator-nightly, google-pasta, tb-nightly, tensorflow-gpu\n",
            "Successfully installed google-pasta-0.1.6 tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kRVATYOgJs1b",
        "colab": {}
      },
      "source": [
        "# Download the file\n",
        "\n",
        "path_to_file = \"keyword-data.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rd0jw-eC3jEh",
        "colab": {}
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.rstrip().strip()\n",
        "\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "opI2GzOt479E",
        "outputId": "35608b40-1d2c-49ad-c123-da04721f4c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "b'<start> puedo tomar prestado este libro ? <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OHn4Dct23jEm",
        "colab": {}
      },
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "    return zip(*word_pairs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cTbSbBz55QtF",
        "outputId": "34cb7996-7ffe-413a-ded3-77a626c3b349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> gmail , google calendar , docs , and talk leave beta <end>\n",
            "<start> google gmail google calendar beta <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OmMZQpdO60dt",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bIOn8RCNDJXG",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eAY9k49G3jE_",
        "colab": {}
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "    # creating cleaned input, output pairs\n",
        "    inp_lang, targ_lang = create_dataset(path, num_examples)\n",
        "\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GOi42V79Ydlr"
      },
      "source": [
        "### Limit the size of the dataset to experiment faster (optional)\n",
        "\n",
        "Training on the complete dataset of >100,000 sentences will take a long time. To train faster, we can limit the size of the dataset to 30,000 sentences (of course, translation quality degrades with less data):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cnxC7q-j3jFD",
        "colab": {}
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4QILQkOs3jFG",
        "outputId": "c7ee5596-4bcd-48d2-8b17-b1412e2944a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1432, 1432, 359, 359)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lJPmLZGMeD5q",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VXukARTDd7MT",
        "outputId": "2e6803c8-6cd7-4ccd-d355-39d015b3e586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "6 ----> best\n",
            "2535 ----> bank\n",
            "11 ----> for\n",
            "473 ----> high\n",
            "1241 ----> interest\n",
            "1242 ----> savings\n",
            "823 ----> accounts\n",
            "14 ----> ?\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "242 ----> savings\n",
            "424 ----> interest\n",
            "242 ----> savings\n",
            "425 ----> accounts\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TqHsArVZ3jFS",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qc6-NK1GtWQt",
        "outputId": "71a393b6-9551-426d-8b8c-ca624b23dad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 23]), TensorShape([64, 15]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## Write the encoder and decoder model\n",
        "\n",
        "Here, we'll implement an encoder-decoder model with attention which you can read about in the TensorFlow [Neural Machine Translation (seq2seq) tutorial](https://www.tensorflow.org/tutorials/seq2seq). This example uses a more recent set of APIs. This notebook implements the [attention equations](https://www.tensorflow.org/tutorials/seq2seq#background_on_the_attention_mechanism) from the seq2seq tutorial. The following diagram shows that each input words is assigned a weight by the attention mechanism which is then used by the decoder to predict the next word in the sentence.\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\" width=\"500\" alt=\"attention mechanism\">\n",
        "\n",
        "The input is put through an encoder model which gives us the encoder output of shape *(batch_size, max_length, hidden_size)* and the encoder hidden state of shape *(batch_size, hidden_size)*.\n",
        "\n",
        "Here are the equations that are implemented:\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\n",
        "\n",
        "We're using *Bahdanau attention*. Lets decide on notation before writing the simplified form:\n",
        "\n",
        "* FC = Fully connected (dense) layer\n",
        "* EO = Encoder output\n",
        "* H = hidden state\n",
        "* X = input to the decoder\n",
        "\n",
        "And the pseudo-code:\n",
        "\n",
        "* `score = FC(tanh(FC(EO) + FC(H)))`\n",
        "* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the *1st axis*, since the shape of score is *(batch_size, max_length, hidden_size)*. `Max_length` is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis.\n",
        "* `context vector = sum(attention weights * EO, axis = 1)`. Same reason as above for choosing axis as 1.\n",
        "* `embedding output` = The input to the decoder X is passed through an embedding layer.\n",
        "* `merged vector = concat(embedding output, context vector)`\n",
        "* This merged vector is then given to the GRU\n",
        "\n",
        "The shapes of all the vectors at each step have been specified in the comments in the code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nZ2rI24i3jFg",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "60gSVh05Jl6l",
        "outputId": "31671bbd-4342-43f4-bf9a-ffd107b3bb8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 23, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "umohpBN2OM94",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # we are doing this to perform addition to calculate the score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, hidden_size)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k534zTHiDjQU",
        "outputId": "8d5d1c2b-e286-49fa-bc73-6022011e027c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 23, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yJ_B3mhW3jFk",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P5UY8wko3jFp",
        "outputId": "04825471-b1df-40d2-bb94-22f4ebcf393c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 760)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "## Define the optimizer and the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WmTHr5iV3jFr",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DMVWzzsfNl4e"
      },
      "source": [
        "## Checkpoints (Object-based saving)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zj8bXQTgNwrF",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hpObfY22IddU"
      },
      "source": [
        "## Training\n",
        "\n",
        "1. Pass the *input* through the *encoder* which return *encoder output* and the *encoder hidden state*.\n",
        "2. The encoder output, encoder hidden state and the decoder input (which is the *start token*) is passed to the decoder.\n",
        "3. The decoder returns the *predictions* and the *decoder hidden state*.\n",
        "4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
        "5. Use *teacher forcing* to decide the next input to the decoder.\n",
        "6. *Teacher forcing* is the technique where the *target word* is passed as the *next input* to the decoder.\n",
        "7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sC9ArXSsVfqn",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ddefjBMa3jF0",
        "outputId": "7b2e49b7-be6c-4d40-aa35-1fc1dd0bc05c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6817
        }
      },
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                     batch,\n",
        "                                                     batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 1.3264\n",
            "Epoch 1 Loss 1.3127\n",
            "Time taken for 1 epoch 20.436784982681274 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.9322\n",
            "Epoch 2 Loss 1.0173\n",
            "Time taken for 1 epoch 3.0138185024261475 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.8330\n",
            "Epoch 3 Loss 0.9506\n",
            "Time taken for 1 epoch 2.519026041030884 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.7903\n",
            "Epoch 4 Loss 0.9080\n",
            "Time taken for 1 epoch 2.881924867630005 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.7716\n",
            "Epoch 5 Loss 0.8761\n",
            "Time taken for 1 epoch 2.5544722080230713 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.7538\n",
            "Epoch 6 Loss 0.8473\n",
            "Time taken for 1 epoch 3.4340648651123047 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.7318\n",
            "Epoch 7 Loss 0.8211\n",
            "Time taken for 1 epoch 2.619783639907837 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.7118\n",
            "Epoch 8 Loss 0.7965\n",
            "Time taken for 1 epoch 2.9488720893859863 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.6938\n",
            "Epoch 9 Loss 0.7736\n",
            "Time taken for 1 epoch 2.5481255054473877 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.6752\n",
            "Epoch 10 Loss 0.7473\n",
            "Time taken for 1 epoch 2.8946220874786377 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.6472\n",
            "Epoch 11 Loss 0.7096\n",
            "Time taken for 1 epoch 2.594940423965454 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.6287\n",
            "Epoch 12 Loss 0.6805\n",
            "Time taken for 1 epoch 2.948852300643921 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.6103\n",
            "Epoch 13 Loss 0.6580\n",
            "Time taken for 1 epoch 2.5949840545654297 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.5738\n",
            "Epoch 14 Loss 0.6305\n",
            "Time taken for 1 epoch 2.9356727600097656 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.5548\n",
            "Epoch 15 Loss 0.5967\n",
            "Time taken for 1 epoch 2.6114134788513184 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.5620\n",
            "Epoch 16 Loss 0.5702\n",
            "Time taken for 1 epoch 3.8798675537109375 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.5041\n",
            "Epoch 17 Loss 0.5370\n",
            "Time taken for 1 epoch 2.6272270679473877 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.4694\n",
            "Epoch 18 Loss 0.4887\n",
            "Time taken for 1 epoch 2.992558479309082 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.4395\n",
            "Epoch 19 Loss 0.4412\n",
            "Time taken for 1 epoch 2.623915433883667 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.4054\n",
            "Epoch 20 Loss 0.4069\n",
            "Time taken for 1 epoch 3.057619333267212 sec\n",
            "\n",
            "Epoch 21 Batch 0 Loss 0.3717\n",
            "Epoch 21 Loss 0.3819\n",
            "Time taken for 1 epoch 2.6337711811065674 sec\n",
            "\n",
            "Epoch 22 Batch 0 Loss 0.3404\n",
            "Epoch 22 Loss 0.3640\n",
            "Time taken for 1 epoch 3.208345890045166 sec\n",
            "\n",
            "Epoch 23 Batch 0 Loss 0.3269\n",
            "Epoch 23 Loss 0.3489\n",
            "Time taken for 1 epoch 2.676395893096924 sec\n",
            "\n",
            "Epoch 24 Batch 0 Loss 0.2898\n",
            "Epoch 24 Loss 0.3235\n",
            "Time taken for 1 epoch 3.1416122913360596 sec\n",
            "\n",
            "Epoch 25 Batch 0 Loss 0.2645\n",
            "Epoch 25 Loss 0.2876\n",
            "Time taken for 1 epoch 2.6692392826080322 sec\n",
            "\n",
            "Epoch 26 Batch 0 Loss 0.2406\n",
            "Epoch 26 Loss 0.2664\n",
            "Time taken for 1 epoch 3.7580668926239014 sec\n",
            "\n",
            "Epoch 27 Batch 0 Loss 0.2054\n",
            "Epoch 27 Loss 0.2372\n",
            "Time taken for 1 epoch 2.6941850185394287 sec\n",
            "\n",
            "Epoch 28 Batch 0 Loss 0.1823\n",
            "Epoch 28 Loss 0.2127\n",
            "Time taken for 1 epoch 3.056490659713745 sec\n",
            "\n",
            "Epoch 29 Batch 0 Loss 0.1538\n",
            "Epoch 29 Loss 0.1641\n",
            "Time taken for 1 epoch 2.674464464187622 sec\n",
            "\n",
            "Epoch 30 Batch 0 Loss 0.1074\n",
            "Epoch 30 Loss 0.1338\n",
            "Time taken for 1 epoch 3.0744194984436035 sec\n",
            "\n",
            "Epoch 31 Batch 0 Loss 0.0910\n",
            "Epoch 31 Loss 0.1130\n",
            "Time taken for 1 epoch 2.6865153312683105 sec\n",
            "\n",
            "Epoch 32 Batch 0 Loss 0.0697\n",
            "Epoch 32 Loss 0.1019\n",
            "Time taken for 1 epoch 3.118769407272339 sec\n",
            "\n",
            "Epoch 33 Batch 0 Loss 0.0481\n",
            "Epoch 33 Loss 0.0877\n",
            "Time taken for 1 epoch 2.7188589572906494 sec\n",
            "\n",
            "Epoch 34 Batch 0 Loss 0.0567\n",
            "Epoch 34 Loss 0.0782\n",
            "Time taken for 1 epoch 3.1030635833740234 sec\n",
            "\n",
            "Epoch 35 Batch 0 Loss 0.0492\n",
            "Epoch 35 Loss 0.0700\n",
            "Time taken for 1 epoch 2.6960785388946533 sec\n",
            "\n",
            "Epoch 36 Batch 0 Loss 0.0302\n",
            "Epoch 36 Loss 0.0639\n",
            "Time taken for 1 epoch 3.1402299404144287 sec\n",
            "\n",
            "Epoch 37 Batch 0 Loss 0.0356\n",
            "Epoch 37 Loss 0.0546\n",
            "Time taken for 1 epoch 2.6875789165496826 sec\n",
            "\n",
            "Epoch 38 Batch 0 Loss 0.0316\n",
            "Epoch 38 Loss 0.0458\n",
            "Time taken for 1 epoch 3.078701972961426 sec\n",
            "\n",
            "Epoch 39 Batch 0 Loss 0.0151\n",
            "Epoch 39 Loss 0.0408\n",
            "Time taken for 1 epoch 2.670743942260742 sec\n",
            "\n",
            "Epoch 40 Batch 0 Loss 0.0189\n",
            "Epoch 40 Loss 0.0353\n",
            "Time taken for 1 epoch 3.071744441986084 sec\n",
            "\n",
            "Epoch 41 Batch 0 Loss 0.0198\n",
            "Epoch 41 Loss 0.0335\n",
            "Time taken for 1 epoch 2.671170234680176 sec\n",
            "\n",
            "Epoch 42 Batch 0 Loss 0.0150\n",
            "Epoch 42 Loss 0.0346\n",
            "Time taken for 1 epoch 3.1054062843322754 sec\n",
            "\n",
            "Epoch 43 Batch 0 Loss 0.0198\n",
            "Epoch 43 Loss 0.0315\n",
            "Time taken for 1 epoch 2.6501729488372803 sec\n",
            "\n",
            "Epoch 44 Batch 0 Loss 0.0172\n",
            "Epoch 44 Loss 0.0296\n",
            "Time taken for 1 epoch 3.1496663093566895 sec\n",
            "\n",
            "Epoch 45 Batch 0 Loss 0.0109\n",
            "Epoch 45 Loss 0.0306\n",
            "Time taken for 1 epoch 2.69903564453125 sec\n",
            "\n",
            "Epoch 46 Batch 0 Loss 0.0105\n",
            "Epoch 46 Loss 0.0322\n",
            "Time taken for 1 epoch 3.0884854793548584 sec\n",
            "\n",
            "Epoch 47 Batch 0 Loss 0.0146\n",
            "Epoch 47 Loss 0.0322\n",
            "Time taken for 1 epoch 2.6746444702148438 sec\n",
            "\n",
            "Epoch 48 Batch 0 Loss 0.0148\n",
            "Epoch 48 Loss 0.0289\n",
            "Time taken for 1 epoch 3.0961642265319824 sec\n",
            "\n",
            "Epoch 49 Batch 0 Loss 0.0173\n",
            "Epoch 49 Loss 0.0288\n",
            "Time taken for 1 epoch 2.6733171939849854 sec\n",
            "\n",
            "Epoch 50 Batch 0 Loss 0.0172\n",
            "Epoch 50 Loss 0.0275\n",
            "Time taken for 1 epoch 3.119947671890259 sec\n",
            "\n",
            "Epoch 51 Batch 0 Loss 0.0127\n",
            "Epoch 51 Loss 0.0308\n",
            "Time taken for 1 epoch 2.6790308952331543 sec\n",
            "\n",
            "Epoch 52 Batch 0 Loss 0.0089\n",
            "Epoch 52 Loss 0.0310\n",
            "Time taken for 1 epoch 3.0703611373901367 sec\n",
            "\n",
            "Epoch 53 Batch 0 Loss 0.0076\n",
            "Epoch 53 Loss 0.0252\n",
            "Time taken for 1 epoch 2.661372661590576 sec\n",
            "\n",
            "Epoch 54 Batch 0 Loss 0.0139\n",
            "Epoch 54 Loss 0.0234\n",
            "Time taken for 1 epoch 3.0437123775482178 sec\n",
            "\n",
            "Epoch 55 Batch 0 Loss 0.0102\n",
            "Epoch 55 Loss 0.0223\n",
            "Time taken for 1 epoch 2.6656413078308105 sec\n",
            "\n",
            "Epoch 56 Batch 0 Loss 0.0115\n",
            "Epoch 56 Loss 0.0210\n",
            "Time taken for 1 epoch 3.071354866027832 sec\n",
            "\n",
            "Epoch 57 Batch 0 Loss 0.0116\n",
            "Epoch 57 Loss 0.0189\n",
            "Time taken for 1 epoch 2.661430597305298 sec\n",
            "\n",
            "Epoch 58 Batch 0 Loss 0.0131\n",
            "Epoch 58 Loss 0.0160\n",
            "Time taken for 1 epoch 3.0791571140289307 sec\n",
            "\n",
            "Epoch 59 Batch 0 Loss 0.0082\n",
            "Epoch 59 Loss 0.0134\n",
            "Time taken for 1 epoch 2.686941146850586 sec\n",
            "\n",
            "Epoch 60 Batch 0 Loss 0.0022\n",
            "Epoch 60 Loss 0.0101\n",
            "Time taken for 1 epoch 4.411203622817993 sec\n",
            "\n",
            "Epoch 61 Batch 0 Loss 0.0036\n",
            "Epoch 61 Loss 0.0103\n",
            "Time taken for 1 epoch 2.7633538246154785 sec\n",
            "\n",
            "Epoch 62 Batch 0 Loss 0.0014\n",
            "Epoch 62 Loss 0.0077\n",
            "Time taken for 1 epoch 3.083139181137085 sec\n",
            "\n",
            "Epoch 63 Batch 0 Loss 0.0016\n",
            "Epoch 63 Loss 0.0078\n",
            "Time taken for 1 epoch 2.689650058746338 sec\n",
            "\n",
            "Epoch 64 Batch 0 Loss 0.0011\n",
            "Epoch 64 Loss 0.0072\n",
            "Time taken for 1 epoch 4.1665215492248535 sec\n",
            "\n",
            "Epoch 65 Batch 0 Loss 0.0012\n",
            "Epoch 65 Loss 0.0058\n",
            "Time taken for 1 epoch 2.6942715644836426 sec\n",
            "\n",
            "Epoch 66 Batch 0 Loss 0.0009\n",
            "Epoch 66 Loss 0.0049\n",
            "Time taken for 1 epoch 3.077727794647217 sec\n",
            "\n",
            "Epoch 67 Batch 0 Loss 0.0009\n",
            "Epoch 67 Loss 0.0046\n",
            "Time taken for 1 epoch 2.665529489517212 sec\n",
            "\n",
            "Epoch 68 Batch 0 Loss 0.0008\n",
            "Epoch 68 Loss 0.0041\n",
            "Time taken for 1 epoch 3.189718008041382 sec\n",
            "\n",
            "Epoch 69 Batch 0 Loss 0.0007\n",
            "Epoch 69 Loss 0.0036\n",
            "Time taken for 1 epoch 2.676623582839966 sec\n",
            "\n",
            "Epoch 70 Batch 0 Loss 0.0007\n",
            "Epoch 70 Loss 0.0038\n",
            "Time taken for 1 epoch 3.0937933921813965 sec\n",
            "\n",
            "Epoch 71 Batch 0 Loss 0.0007\n",
            "Epoch 71 Loss 0.0034\n",
            "Time taken for 1 epoch 2.6575510501861572 sec\n",
            "\n",
            "Epoch 72 Batch 0 Loss 0.0007\n",
            "Epoch 72 Loss 0.0032\n",
            "Time taken for 1 epoch 3.084087371826172 sec\n",
            "\n",
            "Epoch 73 Batch 0 Loss 0.0006\n",
            "Epoch 73 Loss 0.0027\n",
            "Time taken for 1 epoch 2.652198314666748 sec\n",
            "\n",
            "Epoch 74 Batch 0 Loss 0.0005\n",
            "Epoch 74 Loss 0.0028\n",
            "Time taken for 1 epoch 3.0657737255096436 sec\n",
            "\n",
            "Epoch 75 Batch 0 Loss 0.0005\n",
            "Epoch 75 Loss 0.0027\n",
            "Time taken for 1 epoch 2.6779887676239014 sec\n",
            "\n",
            "Epoch 76 Batch 0 Loss 0.0008\n",
            "Epoch 76 Loss 0.0039\n",
            "Time taken for 1 epoch 3.155811309814453 sec\n",
            "\n",
            "Epoch 77 Batch 0 Loss 0.0007\n",
            "Epoch 77 Loss 0.0047\n",
            "Time taken for 1 epoch 2.6561317443847656 sec\n",
            "\n",
            "Epoch 78 Batch 0 Loss 0.0009\n",
            "Epoch 78 Loss 0.0050\n",
            "Time taken for 1 epoch 3.21461820602417 sec\n",
            "\n",
            "Epoch 79 Batch 0 Loss 0.0008\n",
            "Epoch 79 Loss 0.0034\n",
            "Time taken for 1 epoch 2.671245813369751 sec\n",
            "\n",
            "Epoch 80 Batch 0 Loss 0.0006\n",
            "Epoch 80 Loss 0.0038\n",
            "Time taken for 1 epoch 3.0491890907287598 sec\n",
            "\n",
            "Epoch 81 Batch 0 Loss 0.0007\n",
            "Epoch 81 Loss 0.0058\n",
            "Time taken for 1 epoch 2.650644063949585 sec\n",
            "\n",
            "Epoch 82 Batch 0 Loss 0.0012\n",
            "Epoch 82 Loss 0.0067\n",
            "Time taken for 1 epoch 3.138676881790161 sec\n",
            "\n",
            "Epoch 83 Batch 0 Loss 0.0009\n",
            "Epoch 83 Loss 0.0064\n",
            "Time taken for 1 epoch 2.6564652919769287 sec\n",
            "\n",
            "Epoch 84 Batch 0 Loss 0.0015\n",
            "Epoch 84 Loss 0.0069\n",
            "Time taken for 1 epoch 3.021768093109131 sec\n",
            "\n",
            "Epoch 85 Batch 0 Loss 0.0016\n",
            "Epoch 85 Loss 0.0075\n",
            "Time taken for 1 epoch 2.6542110443115234 sec\n",
            "\n",
            "Epoch 86 Batch 0 Loss 0.0007\n",
            "Epoch 86 Loss 0.0088\n",
            "Time taken for 1 epoch 3.1514875888824463 sec\n",
            "\n",
            "Epoch 87 Batch 0 Loss 0.0010\n",
            "Epoch 87 Loss 0.0115\n",
            "Time taken for 1 epoch 2.655411958694458 sec\n",
            "\n",
            "Epoch 88 Batch 0 Loss 0.0052\n",
            "Epoch 88 Loss 0.0128\n",
            "Time taken for 1 epoch 3.0347142219543457 sec\n",
            "\n",
            "Epoch 89 Batch 0 Loss 0.0078\n",
            "Epoch 89 Loss 0.0141\n",
            "Time taken for 1 epoch 2.691873788833618 sec\n",
            "\n",
            "Epoch 90 Batch 0 Loss 0.0065\n",
            "Epoch 90 Loss 0.0165\n",
            "Time taken for 1 epoch 3.0507168769836426 sec\n",
            "\n",
            "Epoch 91 Batch 0 Loss 0.0052\n",
            "Epoch 91 Loss 0.0238\n",
            "Time taken for 1 epoch 2.664639711380005 sec\n",
            "\n",
            "Epoch 92 Batch 0 Loss 0.0123\n",
            "Epoch 92 Loss 0.0223\n",
            "Time taken for 1 epoch 3.0382261276245117 sec\n",
            "\n",
            "Epoch 93 Batch 0 Loss 0.0143\n",
            "Epoch 93 Loss 0.0212\n",
            "Time taken for 1 epoch 2.6649129390716553 sec\n",
            "\n",
            "Epoch 94 Batch 0 Loss 0.0086\n",
            "Epoch 94 Loss 0.0188\n",
            "Time taken for 1 epoch 3.0904459953308105 sec\n",
            "\n",
            "Epoch 95 Batch 0 Loss 0.0045\n",
            "Epoch 95 Loss 0.0211\n",
            "Time taken for 1 epoch 2.6578028202056885 sec\n",
            "\n",
            "Epoch 96 Batch 0 Loss 0.0137\n",
            "Epoch 96 Loss 0.0199\n",
            "Time taken for 1 epoch 3.419660806655884 sec\n",
            "\n",
            "Epoch 97 Batch 0 Loss 0.0142\n",
            "Epoch 97 Loss 0.0179\n",
            "Time taken for 1 epoch 2.6765246391296387 sec\n",
            "\n",
            "Epoch 98 Batch 0 Loss 0.0134\n",
            "Epoch 98 Loss 0.0165\n",
            "Time taken for 1 epoch 3.058131694793701 sec\n",
            "\n",
            "Epoch 99 Batch 0 Loss 0.0163\n",
            "Epoch 99 Loss 0.0201\n",
            "Time taken for 1 epoch 2.661160469055176 sec\n",
            "\n",
            "Epoch 100 Batch 0 Loss 0.0177\n",
            "Epoch 100 Loss 0.0195\n",
            "Time taken for 1 epoch 3.0816614627838135 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "## Translate\n",
        "\n",
        "* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
        "* Stop predicting when the model predicts the *end token*.\n",
        "* And store the *attention weights for every time step*.\n",
        "\n",
        "Note: The encoder output is calculated only once for one input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EbQpyYs13jF_",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                           maxlen=max_length_inp,\n",
        "                                                           padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s5hQWlbN3jGF",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sl9zUHzg3jGI",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n250XbnjOaqP"
      },
      "source": [
        "## Restore the latest checkpoint and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UJpT9D5_OgP6",
        "outputId": "49efda67-3270-4fc0-c76a-75e4822213b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fb3a0320b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WrAM0FDomq3E",
        "outputId": "3821e43f-3c82-4d23-c774-3ab706cc7986",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "translate(u'web store link shows up in chrome, webapps likely coming soon')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> web store link shows up in chrome , webapps likely coming soon <end>\n",
            "Predicted translation: chrome web store webapps <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoUAAAFACAYAAADK5AZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zSx2iM36EZQZ",
        "outputId": "62c3570a-d168-40d0-8956-eb8c3499ac56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "translate(u'run google chrome in ubuntu with wine')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> run google chrome in ubuntu with wine <end>\n",
            "Predicted translation: google chrome ubuntu wine <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnsAAAHFCAYAAACKHD8PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiSpYYY9SZKkhhn2JEmSGvb/A7NSQfQpG38AAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezSIgLe9GEGW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "270f40d6-346a-434c-ed5c-a428c42fa0de"
      },
      "source": [
        "translate('master multiple firefox profiles for more productive browsing')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> master multiple firefox profiles for more productive browsing <end>\n",
            "Predicted translation: firefox profiles <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnsAAAExCAYAAAAEH2QAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHjlJREFUeJzt3XmYZVV97vHvyywoKAQFuRKRwQmQ\nQBsCREW4CQ5cYxS8RkDUSGuioJCIIQZwQg2ighgRVDQIydUgKomJOKBgQGJADSJERRDFBgGB0M0s\n/O4fe7cURXV3VQ9n11n1/TxPPdRZZ599fsWmDm+ttfZaqSokSZLUptWGLkCSJEmrjmFPkiSpYYY9\nSZKkhhn2JEmSGmbYkyRJaphhT5IkqWGGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlhhj1Jc0KS5yb5\nlySXJ3lc3/bqJHsOXZskrUqGPUnNS7If8Bngx8AWwJr9U6sDhw9VlySNgmFvAEm2TnJuku2GrkWa\nIw4HDqqqQ4FfT2i/CNhhmJIkaTQMe8M4ENgdeNXAdUhzxdbAt6ZoXwSsP+JaJGmkDHsjliTAAcCp\nwMuSrD5wSdJcsADYZor2ZwI/GXEtkjRShr3R2x14BHAI3XDS8watRpobTgE+mGS3/vHjkhwIHAuc\nNFxZUtuSrJZktQmPN+lvjNptaa/TypWqGrqGOSXJJ4F7qmp+kvcBv11V+wxcltS8JMcAhwLr9E13\nA8dV1ZHDVSW1Lcm/AV+qqhOSPBz4b2A94OHAn1bVaYMWOEcY9kYoyXrAdcDzq+qbSXagm0e0aVXd\nOmx1WpIkawLHAH9XVdcMXY+WX5J1gafQjWpcXlWLBi5JalqSG4E9qur7SV4O/BXwNGA/4LCq2n7Q\nAucIh3FH68XATVX1TYCq+h7dUhAvHbQqLVVV3Qv8OZCha9GKqao7quriqvq2QU8aiYcDizsz/hD4\nXP+Zei6w5WBVzTFrDF3AHHMAcPqkttOBVwAfGXk1molzgD3obqzRGEhy9nSPraoXrMpapDnsZ8Bu\nSf4Z2AvYt2/fELhjsKrmGMPeiPQr9j+brodoon8A3pVkm6r60egr0zR9je46bQ9cAtw+8cmqOmuQ\nqrQ0vxq6AEm8H/gU3TJH1wDn9+3PBL4/VFFzjXP2pGlIcv9Snq6qcgkdaSVLsnNV/ccSnntJVX1m\n1DVp5pLMAx4HfGXx9IkkzwduraoLBi1ujjDsjVCSzYGf1xT/0pNsXlU/G6Asac5I8jAemCf0k6q6\nc8h6tHRJ7gbeARyz+HOzv6Pzw8CLq2q9IeuTxoU3aIzW1cDGkxuTbNQ/J2kVSLJ2kuOBm4H/Ai4F\nbk5yQpJ1lv5qDeiPgNcB5yXZPMmudNdue+B3B61M05bkz5P8IMkdSZ7Qt705yUuGrm2uMOyNVoCp\nulIfDtw14lo0A+lM9YH1V35gjYWTgH2AV9NtnbZV//0f0/USaRaqqi/RBbvb6OZ3fR34PPC7VfWD\nIWvT9CR5I/A3dAubT1zRYAHw+kGKmoO8QWMEknyw/7aAdyeZeAfS6nR/oX5v5IVpJt4AHA78LfCe\nCe2/oPvAcu7Q7LYv8KKq+sqEtquS3AB8Fvepns3WAzYC7gEeBtwJ3DdoRZqJ1wIHVdUXk7xzQvt3\ngKcOVNOcY8/eaGzXfwV48oTH29H1MHyHbvkVzV6LP7BOoNvmbjE/sMbD7XTBfLJf0IUHzUJJDqAb\ndl8APBH4A2B/4KIkWw9Zm6btt4HLpmi/ly68awTs2RuBqnp2ktD1/ryqqhYOXZNmzA+s8XYicHSS\nVyy+KaO/WePI/jnNTicBh1bVR/vH5/XLH50MfJduCoxmt6uAHemWXZnoecDloy9nbjLsjc5qwAuB\no/E/8HHkB9Z4+z3gWcAvklzat21H9xm43sQFmF1geVbZcfL6o1X1P8BLk+w/UE2ameOAD/VbFQbY\npe+xPRynT4yMYW9Equq+JNcAaw1di5aLH1jj7Sa6uXkTeQf8LDcx6PVLrlRV3d4/N3k3Is1CVfWJ\nJGsA7wLWpVtgeQFwSFV9etDi5hDX2RuhJAcCfwLsX1U3DV2PZibJQXR3lT2ub1oAHF1VHx+uKqlt\nSV4HvBnYrG+6FvjbqvIu6jGT5LeA1arqhqFrmWsMeyOU5PvAFsCadB9Yk7fc2n6IujQzfmBJo5Hk\nr4Ej6HrW/71vfgZwGPCuqnrPkl4r6QEO447WmUMXoOWT5Fy6pTtundgrm2R94PNVtcdw1Wkq/dy8\nZ1XVLf0fWkv8y9Y/tGat1wLzq+ofJ7R9LcmP6YYFDXuz0LJ+3ybyd280DHsjVFVvG7oGLbfdmXq+\n5Tp0PQ2afT4L3D3he4cxxs+jgf+cov3bwGNGXIumz46NWcZhXGkpkuzYf3sx8Id0220ttjqwF/Dq\nqnr8iEuTmtf3zp5ZVW+f1H40XU/704apTBov9uyNUJK1gLfQ3aSxOd3cvd+oqtWHqEtLdTFdj1AB\nX57i+TuBg0dakWZs4jD8pHaH4We3twKfSfJM4IK+bTe6ZXT2HaooadwY9kbrHcD/Bd4NfAB4E/B4\n4KV0i7tq9tmCbqmVq+i2tbtxwnP3ADdUlVs3zX674zD82Kmqs5LsDBwK7N03X0G3N+53h6tMS+N8\n2dnHsDdaLwFeW1VfSnIc8IWq+kmSK+i2ATp52PI0WVUtXkTZrQXH0IRheIDtk0w1DD/VNmoaSJJT\ngTdU1cK+R+/CqnIB5fHifNlZxjl7I5TkDuBJVfWzJNcBe1fVJUm2AP6rqtYfuEQtQZKXALdW1Zf7\nx0cB84EfAK+oquuGrE9TS3I/D/yPJlMccidwcFWdOrqqtDRJ7gE2r6rrk9wHbOoyR+MlycuBT1fV\n3cs8WCNhz95o/Qx4bP/PK+l6FS4BdsHN2Ge7twJvhN/0Fv01cBTwHOB9wMsGq0xL4zD8+PkpcHCS\nL/PAbjW3THVgVZ0/ysI0bZ8A/g240cA+O9izN0JJ3g0sqqpjkuwD/CPd4sqbAe+tqrcMWqCWKMnt\nwFOq6pok7wC2rqqXJtkBOKeqXAZCWgmS/BHwMWAjul7ZqXpkods6zZvaZqEk19Otj3h237v+mKq6\ncVmv06pj2BtQP/F4N+BHVfUvQ9ejJUvyK7oJx5cluRA4tao+1g/B/6Cq1h24RE2S5EXTPbaqzlqV\ntWjmkjySbqmjpwJT9gpV1a9GWpSmJclb6UY+lhkwDOyjYdgboQmTjX89qX0NYFeHJGavJJ8HHka3\nZdORwOOrakGSvYAPVtUTBy1QD9H3KEyHPUSzVJJnARdM/szU7JfkqcDWwFnAQcCtUx1XVZ8dZV1z\nlWFvhJY0dyHJRnRzh/wfziyV5H8BJ9Gtj3jC4gn9SY6n2yf3kCHrk1qV5DHAAcCWwJFVdVOS3YAF\nVXX1sNVpWfoFsN9bVXcMXctcZtgboSXNXUiyDXCxd+NK0gOS7AR8Dbiabjj3SVV1VT9MuE1VeWPU\nmEjyBOApdEO7V1TVVQOXNKd4N+4IJDm7/7aA05NMvB19dWBb4MKRFybNEcuav+ecvVnrOLqe9KOT\nLJzQfg7wyoFq0gwkeQRwKvBi4P4HmvNZ4E+rauESX6yVxrA3GosnEQe4hQcvs3IP3Tywj466KE2f\nW92NvSVtzL54aMPrNzvtBPzpFO3XAd4BPx4+CGwPPJsHOjV2Az4CHM/U11crmWFvBKrqlQBJfgoc\nV1W3D1uRloNb3Y2xqnrQDij9TVG/A7yXLsRrdroTeNQU7U9iCXfoatZ5AfDCqvrmhLZvJJkPfA7D\n3kg4Z2+EkqwGUFX39483odvv8fKqchh3FktyNfBn/VZ3C4Ed+q3u/gzYs6r2GbhELYckuwInVdXT\nhq5FD5XkFGATYF/gJroeogK+AJxbVYcOWJ6mod85al5VXT6pfVvgP6pqvWEqm1vc73O0vggcDJDk\n4cDFdD0L5/Xby2j2egyw+MNqEfDI/vsvAX84SEVaGW6lu8tTs9NfAhvS7XyyLt2UlyvprtvfDFiX\npu8C4B1JfrMWaZL1gLfhXPWRcRh3tOYBh/ffvwi4jW47p/3oPtROG6guLZtb3Y2xfou7BzUBmwJv\nBr47+oo0HVV1G/D7SfYAdqTroPhOVX112Mo0A4fR/VH8iySX9m3bAXfQfY5qBBzGHaEkd9ItF/Dz\nJKcD11TVW5JsTncrut3Zs5Rb3Y23ftmjqbbeugh4VVX99+ir0tIkWZOuJ+/lVfXDoevR8ut79faj\nm2sJcAVwRlX5h/KI2LM3Wj8Ddkvyz3R/0ezbt29I91eOZqmqOmLC92cm+TludTdOtpj0+H7gxqq6\na4hitGxVdW+/HaE9EmOqD+ynA39dVa44MSB79kYoyWuAD9HN+boG2LGq7k9yCN3dSnsMWqCWql/J\nfzfg0Tx4vmtV1UnDVKXpWsr1o6o+PEhRWqok7wWoqjcNXYuWT5JbgJ1cRHlYhr0R61eE3xz4SlUt\n6tueD9xaVRcMWpyWKMn+wMd4YK3Eib84VVWPHaQwTYvXbzwl+TDd8N/VdHNkH7RsldsUzn5JPk43\nTem4oWuZywx7I5JkA2D7SWsNLX5uN7rlV24ZfWWajiTXAH8PvN1N2ceP1288Jfn6Up4uR0Nmv35v\n3EOB8+hWoJgc2N8/RF1zjWFvRPotY64D9prYg5fkacC3gc2q6qah6tPSORQx3rx+0jD6NUqXpKrq\nCSMrZg4z7I1QkjPo7uh8zYS24+ju0H3BcJVpWZJ8CPhhVZ04dC2aOa+fNLx+fVkWT2HS6Bj2RijJ\nXnRLdmxSVff0O2pcC7zejdhnt35v3M/T7WX8feDeic9X1duHqEvT4/UbH0nOBvavqtv6lQuW+D8p\n/0geD0neSLfe3mZ90wLg/cDxZQgZCZdeGa2v0C3AuzdwFrAnsBbwz0MWpWl5DfAcui2btmLSBH/A\nsDC7ef3Gx7Y8cH2c2jLmkhwLzKfbLepbffMuwFF0C5sfvoSXaiWyZ2/Ekvwt8MSqemGS04CFVfW6\noevS0iW5AXh3VX1g6Fo0c16/8dEvgL1JVd2Q5Crg6VX1q6Hr0vJJcjMwv6rOnNS+D3ByVW00TGVz\niz17o3cacEm/a8Yf0/XuafZbHTh76CK03Lx+4+NmukWwbwAej3u4t+DSJbR5bUfEnr0BJLmYbjj3\nt6rqyUPXo2Xrb6S5zbld48nrNz6SnAwcSLd6weZ085rvm+pY7+Sc/ZIcT5c13jCp/QPA6q6VOBr2\n7A3jNOB4wP1Ux8e6wKv7m2wu5aET/P3Amt28fuPjtXS9sFvTTeL/BLBw0Iq0ItYGXtb/7l3Ut+0M\nPBY4I8kHFx/o7+GqY8/eAJJsCBxMN1/h+qHr0bK5uOt48/qNpySfAA6pKsPemFrG795E/h6uQoY9\nSZKkhjk5UpIkqWGGvYEkmT90DVp+Xr/x5bUbb16/8eb1G4Zhbzj+Bz/evH7jy2s33rx+483rNwDD\nniRJUsO8QaO3VtaudVhvZO93L3ezJmuP7P20cnn9xpfXbrx5/cbbKK/fltsvGsn7DOV7l957U1Vt\nPJ1jXWevtw7rsXPczEKSpBZ89t8uWvZBY2yDza69ZrrHOowrSZLUMMOeJElSwwx7kiRJDTPsSZIk\nNcywJ0mS1DDDniRJUsMMe5IkSQ0z7EmSJDXMsCdJktQww54kSVLDDHuSJEkNM+xJkiQ1zLAnSZLU\nMMOeJElSwwx7kiRJDTPsSZIkNcywJ0mS1DDDniRJUsMMe5IkSQ0z7EmSJDXMsCdJktSwFQ57SVZL\ncnKSXyWpJD9N8i8ro7gkf5Tkx0l+neSTK+OckiRJc8kaK+EczwNeCewOXAXcCWQlnBfg48DHgBOB\nRSvpnJIkSXPGygh7WwHXVdWF0zk4yVpVdc80jnsksBFwTlX9YgVrlCRJmpNWaBi3H1r9ALD5hCHc\nT04cxk3yjSQnJTkuyY3ABX37BklOSXJDkoVJzksyr39ud+CW/hTn9ufevX/uRUm+n+TuJD9P8pYk\n6Z97YpLbkxw44f2fk+SeJLusyM8qSZI0jlZ0zt4bgLcD1wKbAk9fwnH70w3tPgN4eR/OvghsBuwN\n/A5wPl2w2xS4EHhq/9oX9+e+MMlOwD8BZwHbAX8FHAG8HqCqfggcCpyY5AlJNgY+CRxTVd9awZ9V\nkiRp7KzQMG5V/U+ShcB9VXU9QN/JNtnVVfUXix8k2QPYAdi4qu7sm49M8n+AA6rq2CQ39O03Tzj3\nYcB5VXV0/9yPkmwNvJluXh9VdUqS5wL/APwK+AnwzqmKSjIfmA+wDusu178DSZKk2WxUS69cMunx\nTsC6wI1JFi3+ArYFtlzKeZ5MPww8wb8DmyVZf0Lbq+nmEj4T2L+q7pvqZFV1SlXNq6p5a7L2DH4c\nSZKk8bAybtCYjtsnPV4N+CXdsO5kty3ne9SE77cFNui/3wy4ejnPKUmSNNZGFfYm+w7wGOD+qrpq\nBq+7AthtUtvvA9dW1UL4zV28nwKOAx4GfCrJ06pqeUOkJEnS2BpqB42v0g3HfiHJc5NskWSXJG9L\nMlVv32LvA56V5K1JtkmyH/AXwLETjvkIcCNwFN1cvoXA362aH0OSJGl2GyTsVVXRLcZ8LvBR4IfA\nZ4AnAguW8rrvAPvS3aF7GfCe/utDAEkOAF4A7FdV91bV3cDLgH2SvHSV/UCSJEmzVLrcpfWzYe2c\nPYcuQ5IkrQSfvfaioUtYpTbY7NpLqmredI4dahhXkiRJI2DYkyRJaphhT5IkqWGGPUmSpIYZ9iRJ\nkhpm2JMkSWqYYU+SJKlhhj1JkqSGGfYkSZIaZtiTJElqmGFPkiSpYYY9SZKkhhn2JEmSGmbYkyRJ\naphhT5IkqWGGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlhhj1JkqSGrTF0AZKWIRm6glWraugKpCU6\nZ8H3hi5hlXnuVrsOXcIqte9Wuw9dwip2+rSPtGdPkiSpYYY9SZKkhhn2JEmSGmbYkyRJaphhT5Ik\nqWGGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlhhj1JkqSGGfYkSZIaZtiTJElqmGFPkiSpYYY9SZKk\nhhn2JEmSGmbYkyRJaphhT5IkqWGGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlhhj1JkqSGGfYkSZIa\nNmjYS/LWJL9MUkle0T++bNLzly3tHJIkSVqyNYZ64yTbAkcDLwK+BfwPsDpw4lA1SZIktWalh70k\na1XVPdM4dKv+n5+vqprQvmhl1yRJkjRXLXMYN8k3knwkyQlJbum/3ptktf75n/bDracmuRU4o2/f\nLslXk9yZ5OYkn0yyQf/cW4HP9W9xf5Ja3L6sYdskr0xyeZK7kvwoyaGLa+mff03ffleSm5Kck2Sw\nHkxJkqQhTTcE7Qd8EtgF2B74KHAd8P7++cOAdwLzgCRZDzgH+Dbwu8CG/WtOBV4MHAdc27dtOt1i\nkxwEvB04GLgE2LY/x73Ah5LMA/4OOBD4d+CRwB7TPb8kSVJrphv2rgMO6Ydb/zvJNnQBb3HYO6+q\njl18cB/K1gMOqKqFfdt84OtJtqqqK/teQKrq+hnUeyRweFWd2T++Osl7gD8HPgRsDtwOnN2/7zXA\nfy3pZH1N8wHWYd0ZlCFJkjQepns37kWT5tV9C9gsyfr944snHf9k4NLFQa93IXA/8JTlKTTJxsDj\ngJOTLFr8BbwH2LI/7Ct0Ae/qJGckOTDJI5Z0zqo6parmVdW8NVl7ecqSJEma1VbWXLbbZ3BsLfuQ\nKS0Opq+lC44PPXHVwiQ7As8E/gA4AnhXkqdX1YLlfF9JkqSxNd2evZ2TZMLj3wMWVNVtSzj+CmC7\nSb1qu/bvd8XMy4Sq+iWwANiyqq6c/DXhuF9X1blVdQTd/ML1gL2X5z0lSZLG3XR79h4LHJ/kw8B2\nwJvobshYkjOAtwGnJTkKeBRwMnDWxGC2HI4GTuzn+/0rsCawI7BZVb07yd50Q7rnAzcDzwYewXIG\nTEmSpHE33bB3Bt2Cx/9BNwz7ceADSzq4qu5IshdwPN0duXcBXwDesCLFVtXHktxOFzbfDdwJ/IDu\n5gyAW4EXAkcB6wI/AV5dVd9ckfeVJEkaV3nwfRdTHJB8A7isql4/kooGsn42rJ2z59BlSA/1oBkU\nDVrGZ5A0pHMWfG/oElaZ526169AlrFr33z90BavUl+88/ZKqmjedYwfdG1eSJEmrlmFPkiSpYcuc\ns1dVu4+gDkmSJK0C9uxJkiQ1zLAnSZLUMMOeJElSwwx7kiRJDTPsSZIkNcywJ0mS1DDDniRJUsMM\ne5IkSQ0z7EmSJDXMsCdJktQww54kSVLDDHuSJEkNM+xJkiQ1zLAnSZLUMMOeJElSwwx7kiRJDTPs\nSZIkNWyNoQuQtAxVQ1cgzVl7PXaHoUtYhe4YuoBVasGbdh26hFXr2NOnfag9e5IkSQ0z7EmSJDXM\nsCdJktQww54kSVLDDHuSJEkNM+xJkiQ1zLAnSZLUMMOeJElSwwx7kiRJDTPsSZIkNcywJ0mS1DDD\nniRJUsMMe5IkSQ0z7EmSJDXMsCdJktQww54kSVLDDHuSJEkNM+xJkiQ1zLAnSZLUMMOeJElSwwx7\nkiRJDTPsSZIkNcywJ0mS1LCxC3tJ/jLJT4euQ5IkaRyMXdiTJEnS9K3UsJdk/SSPXJnnnMZ7bpxk\nnVG+pyRJ0rhY4bCXZPUkeyX5B+B64Gl9+wZJTklyQ5KFSc5LMm/C616RZFGSPZNcluT2JF9PssWk\n8x+e5Pr+2NOAh08q4XnA9f177baiP48kSVJLljvsJXlqkmOBnwOfBm4HngOcnyTAF4HNgL2B3wHO\nB85NsumE06wNHAG8CtgFeCTwkQnv8RLgncDRwI7AD4HDJpVyBvAy4BHAV5JcmeSoyaFRkiRpLppR\n2EuyUZJDklwCfBd4EvAGYJOqOqiqzq+qAp4N7ADsU1Xfrqorq+pI4CrggAmnXAN4XX/MpcBxwO59\nWAR4I/D3VXVyVf2oqo4Bvj2xpqr6dVX9a1X9CbAJ8K7+/X+c5BtJXpVkcm/g4p9nfpKLk1x8L3fP\n5F+FJEnSWJhpz97BwAnAXcA2VfWCqvqnqrpr0nE7AesCN/bDr4uSLAK2BbaccNzdVfXDCY8XAGsB\nj+ofPxn41qRzT378G1V1W1WdWlXPBp4OPAb4OLDPEo4/parmVdW8NVl7KT+2JEnSeFpjhsefAtwL\nvBy4LMnngE8BX6uq+yYctxrwS+AZU5zjtgnf/3rSczXh9TOWZG26YeP96eby/YCud/ALy3M+SZKk\ncTejUFVVC6rqmKp6IvC/gUXA/wOuTfK+JDv0h36Hrlft/n4Id+LXDTN4yyuA35vU9qDH6fx+kpPp\nbhA5EbgS2KmqdqyqE6rqlpn8nJIkSa1Y7hs0quqiqvozYFO64d1tgP9M8gzgq8AFwBeSPDfJFkl2\nSfK2/vnpOgE4MMlBSbZOcgSw86Rj9ge+DKwP/AnwuKp6U1Vdtrw/myRJUitmOoz7EFV1N3AmcGaS\nRwP3VVUleR7dnbQfBR5NN6x7AXDaDM796SRPAI6hmwN4NvB+4BUTDvsa3Q0itz30DJIkSXNbuptn\ntX42rJ2z59BlSJKklWDBm3YduoRV6vJjD7ukquYt+0i3S5MkSWqaYU+SJKlhhj1JkqSGGfYkSZIa\nZtiTJElqmGFPkiSpYYY9SZKkhhn2JEmSGmbYkyRJaphhT5IkqWGGPUmSpIYZ9iRJkhpm2JMkSWqY\nYU+SJKlhhj1JkqSGGfYkSZIaZtiTJElqmGFPkiSpYYY9SZKkhhn2JEmSGrbG0AVIkiStbI9974VD\nl7BKXT6DY+3ZkyRJaphhT5IkqWGGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlhhj1JkqSGGfYkSZIa\nZtiTJElqmGFPkiSpYYY9SZKkhhn2JEmSGmbYkyRJaphhT5IkqWGGPUmSpIYZ9iRJkhpm2JMkSWqY\nYU+SJKlhhj1JkqSGGfYkSZIaZtiTJElqmGFPkiSpYYY9SZKkhhn2JEmSGmbYkyRJaphhT5IkqWGG\nPUmSpIatMXQBQ0oyH5gPsA7rDlyNJEnSyjene/aq6pSqmldV89Zk7aHLkSRJWunmdNiTJElqnWFP\nkiSpYYY9SZKkhhn2JEmSGmbYkyRJaphhT5IkqWGGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlhhj1J\nkqSGGfYkSZIaZtiTJElqmGFPkiSpYYY9SZKkhhn2JEmSGmbYkyRJaphhT5IkqWGGPUmSpIYZ9iRJ\nkhpm2JMkSWqYYU+SJKlhhj1JkqSGGfYkSZIaZtiTJElqmGFPkiSpYamqoWuYFZLcCFwzwrf8LeCm\nEb6fVi6v3/jy2o03r9948/qtPL9dVRtP50DD3kCSXFxV84auQ8vH6ze+vHbjzes33rx+w3AYV5Ik\nqWGGPUmSpIYZ9oZzytAFaIV4/caX1268ef3Gm9dvAM7ZkyRJapg9e5IkSQ0z7EmSJDXMsCdJktQw\nw54kSVLDDHuSJEkN+/9sCsRMEn4UCwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A3LLCx3ZE0Ls",
        "outputId": "8c1d3987-fbeb-4ac4-a9ae-5ed6ec76d56d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "translate(u'five best sites for finding deals online')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> five best sites for finding deals online <end>\n",
            "Predicted translation: deals <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAngAAAELCAYAAABKyfvIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DUQVLVqUE1YW",
        "outputId": "252c9f41-4e91-41a0-bcf5-14a2f633b1b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "# wrong translation\n",
        "translate(u'make your own firefox site search plug-in')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> make your own firefox site search plug in <end>\n",
            "Predicted translation: firefox search <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAngAAAEwCAYAAAAkdAymAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHClJREFUeJzt3XeYZGWdt/H7SxAEHDAgYmBFBEUQ\nUBBEFFHWF2QVw5oB0yrqYk67rmvcRUQx8KpL0EXFiOk1KwaSIOoCIgYWRAFFRECRYRCR8Hv/OGek\naHpmusepOt1P35/r6ouuc05V/YozMN96YqoKSZIktWO1oQuQJEnSqmXAkyRJaowBT5IkqTEGPEmS\npMYY8CRJkhpjwJMkSWqMAU+SJKkxBjxJkqTGGPAkSZIaY8CTJElqjAFvQpJsnuS4JPcduhZJktQ2\nA97kPAPYDXj2wHVIkqTGpaqGrqF5SQJcAHwTeDRw56q6YdCiJElSs2zBm4zdgNsALwauB/YatBpJ\nktQ0A95kPAP4TFX9Cfhk/1iSJGks7KIdsyTrAr8F/qGqvpNkO+BUYOOq+uOw1UmSpBbZgjd+/whc\nXlXfAaiqM4GfA08ZtCpJktQsA9747Qd8dMqxjwLPnHwpkiRpIbCLdoyS3A04H9iyqn4+cvyudLNq\n71NV5w5UniRJapQBT5IkrTJJdqqq7y/j3JOq6lOTrmkhsot2zJJs0q+DN+25SdcjSdKYnZTk30f/\n7kuyXpKjgQ8OWNeCYsAbv/OBDaceTHL7/pwkSS15DHAAcGLfyPEg4CxgG2DHQStbQAx44xdgun7w\n9YA/T7gWSZLGqqq+ThfmFgM/Bo4HPg/sWFU/HbK2hWSNoQtoVZL/2/9awEFJ/jRyenW6bzFnTrww\nSZLGb13g9sBfgFsD1wBu0TlBtuCNz337nwBbjjy+L3BP4AxcKkWS1Jgk+wE/Ai4G7gU8AtgX+F6S\nzYesbSFxFu0Y9QNMPwU8u6quGroeSZLGLckS4GVV9f6RY+sDRwCPqqr1BituATHgjVGS1enG2W1b\nVT8buh6tvCR3ADYDzqyqa4euR5LmqiRbLGuN1yT7VtXUxf81BnbRjlFV3QBcCNxq6Fq0cpLcJsmn\ngEuB7wJ36Y8fnuSNQ9YmSXPRaLjrl0dZd+Sc4W5CDHjj9x/AW/sWIM0/B9OFuvvTDRJe6svA4wap\nSJLmuCQHJPkVcCWwOMmFSf556LoWEmfRjt8rgU2B3yS5CLh69GRVbTNIVZqpvYHHVdWZSUbHM5wN\n3GOgmiRpzkryb8BrgEOAk/vDD6Fr7FhUVW8drLgFxIA3fp8ZugD9TW4L/H6a47fBKf+SNJ3nA/tX\n1SdGjn07yc+BtwAGvAkw4I1ZVb1p6Br0N/kfula8d/ePl7biPY9uTJ4k6ebuSPf/zql+AGw04VoW\nLAOetHz/BhybZCu6/15e3v++I7DroJVpmZKsCRwIvK+qLhy6HmmBORd4GvDmKcefBpwz+XIWJpdJ\nGbMktwJeCzwV2ARYc/R8Va0+RF2auST3pRtLuT3dxKQzgIOr6seDFqbl6tfi2rqqLhi6FmkhSfJ4\nujVgTwBO6Q/vAjwUeGJVfX6g0hYUA96YJTkYeDJwEPAu4N+BuwNPAV5XVUcMV51WJMlqVXXjMs4t\nqqrFk65JM5Pks8BXquqooWuRFpok2wMvo9vJCbqJae+oqh8OV9XCYsAbsyTnAy+oqq8nuQrYrqp+\nkeQFwO5V9YSBS9RyJPlgVT1rmuPrA9+oqp0GKEsz0C/J8Hrgk8Dp3HIG++eGqEtqUZKjgJdU1VVJ\ndgW+W1XXD13XQmbAG7MkfwLuXVW/SvJbum1aTk+yKfCjqlo0cIlajiRnA1+uqleNHFsf+CZwZVU9\nYrDitFxJpm157ZXDI+a+JE8GdqcbtH+zdVurau9BitK0kvwF2KSqLklyA7BxVV06dF0LmZMsxu9X\nwJ37f54H7EHXmrAzN184V3PTHsDJSX5fVW9NsgF9uAMeNWxpWp6qciH3eSzJ24GXAsfTbVpva8Tc\ndgHwoiTfAALsnOSK6S6sqpMmWdhCZQvemCU5CFhSVQcmeQLwCeAiut0R3l5Vrx20QK1Qki2Bk+jW\nbnoK8Efg0VX150ELkxqW5HfAAVXlWqLzQJLHAB8Abk8XxrOMS209nxAD3oQl2YluNtG5VfXloevR\nzCTZEfgWcCqwd1VdO3BJWoEkL1/e+ap656Rq0ewluQzYuarOG7oWzVzfy/EHYCu6PbxvoaqmWzxe\nq5gBb8yWNdg0yRrAg2yqnnuS/Jjpu4PuClwG/DXcudXc3NVPcBq1JrAx3dCIS6vKrebmsCQHAtdV\n1RuHrkWzk+ShwClOshiWY/DG73i6v1SmfpNZvz9nU/XcY5dQA6pq06nHkmwEfBB4/+Qr0ixtADwt\nySOAs4DrRk9W1YsHqUorVFUnJtkoyX7AZnRLgl2eZBfg4qqa+uVLY2AL3pj1M/k2qqrLphzfAjjN\nWbTSZCW5H/Cpqtp86Fq0bEmOX87pqqqHT6wYzUq/Bt63gfPpumrvXVW/TPJGYIuqetqQ9S0UtuCN\nSZIv9r8W8NEko2O2Vge2xr1MpSGshvthznlV9bCha9BKOwQ4tKre0K//utSxwC3WFdV4GPDGZ+kg\n0gBXcPMlUf4CnIzdRHOeW83NX/12STc7RDdc4gDgO5OvSLOR5EHADxzHNS9tD/zTNMd/i1+uJsaA\nNyZLdz9IcgFwSFVdvfxnaI76D26+1dyrGNlqbriyNANTx1IW3SSZ44BXTL4czdJxwHVJTqXb0/QE\nDHzzxTXAbac5fm+WMbNWq55j8MYsyWoAS/czTXInugVyf1ZVdtHOcW41Jw0jya25aYP63YAH0E20\nOBU4vqoOGq46LU+SI4E7AU8ELge2ofuC9QXguKp62YDlLRgGvDFL8jXg61V1aJL1gP8F1gXWA/6p\nqo4etEAtl1vNSXNDks3ohkvsC6zu8Ii5K8ki4Kt0wW5d4BK6rtlTgL3s0ZoMt/IZvx3ouhoAHg8s\npttX8bnAK4cqSjO2dKs5uGmrOXCruXkhyT8kOSnJ5UkuS3Jikr2GrksrluSOSZ6U5LB+T+izgE2B\nAwFn0M5hVbW4qh4MPBb4F+BQYM+qeqjhbnJswRuzJNfQTQv/dZKPAhdW1WuTbAKcXVXrDlyilsOt\n5uavJM8B/gv4GN2kJoCH0E2YeUFVHTVUbVqxfompy4Aj6HaR+b47yMx9Sdak++/t6VV1ztD1LGQG\nvDFLcg7wBuBLdJsxP7GqTkiyHfDNqtpwyPo0O241N38k+TndUg3vnXL8RcCLqmqLYSrTTPRfiHel\nWxT+O3QLw58AnFH+xTWnJbkUeHBVnTt0LQuZAW/MkjwPeC+wBLgQuH9V3ZjkxcBjXaxz7ut3P9iF\nrmt9dFhDVdVhw1SlFenXntxq6l6mSe4J/LSq1hqmMs1GP/Zut/5nV2ARcFJVPWbAsrQcSd4OUFWv\nGrqWhcxlUsasqo5IchrdGmrfXDqbFvgFLrMx5yXZF/gAN61nOPqNqAAD3tz1K+ARdGMnR/0fui9b\nmh/OB+5A9wVrI7qgt+eQBWmF1gX26beZOx242bg7t5mbDAPeGCVZH9imqr5D94d81B+Bn02+Ks3S\ngcDbgDe7/ta8cwjwniT356ZdY3YB9gNeNFhVmpEkr6YLcw8G1qb7f+gJwDu4aUyl5qYtgTP63+8x\n5ZzdhhNiF+0YJbkN3crde1TVKSPHtwV+ANylqi4fqj6tWJIrgO2r6pdD16LZS/I4ukWNt+wPnU03\nOeYLw1WlmZiywPHJzr6UZseAN2ZJPkY3C/N5I8cOoZtZu/dwlWkmkrwXOKeq3jN0LZqdJJ+n617/\n6sjQCM0j/fjXA4D70LX8/BQ4rKp+N2hh0jxgwBuzJHvQLa1xp6r6S7+zxUXAC6vqc8NWpxXp96L9\nPN3+wT+mW0n/r6rqzUPUpRXrv1w9FrgS+BBw1NQJF5q7kuwCfI1ua6tT+8M7043F26OqTl3WczV5\nSb4I7FtVi5N8ieV0xdq4MRkGvDHrA92v6ZZl+Fw/6PQTwMZVdd3yn62h9UtqHEq33c6lTJlkUVXb\nDFKYZqRfUX8f4Fl0i46fTNeq9+mqcqHqOazvov0x8PyRrR5XAw4Htq6qBw1Zn24uyS+BbavqqiQf\nXN61S/dq13gZ8CYgycHAvarqsUmOBq6qqgOGrksr1q/ndFBVvWvoWvS3SbIV8Bzg+cC1wDHAu6vq\n7EEL07T6ReK3m7pYbpJ7Az+sqlsPU5mm0y9MfaequrQPew+oqt8PXddC5lZlk3E0sGe/e8XjgA8P\nXI9mbnXgi0MXob9NkjsDjwEeBVwPfBa4G3BWErcMnJuupNuabKpN6VYh0NzyB266X3fHfDE4W/Am\npF8L7xrgDlW15Yqu19zQT4hZ7Fi7+affMukxwLPp1sP7IfB+4BNVtaS/Zm/g6KraYLBCNa0k7wae\nCLyamy9zczBwTFW9fKjadEtJjgCeQbdyxCZ0Y81vmO7aqpq6dIrGwHXwJudo4N2Ae5fOL+sAz+kn\ny5zFLSdZuGDn3PVbugWqPw78a1WdNc01J9EtYK2559V09+8obvq76jq6xcX/daiitEzPp+vt2Bx4\nJ/BB4KpBK1rgbMGbkCS3o1tc9YiqumToejQzSY5fzulyq7m5K8l+dJMp/jx0LVp5SdYBNusf/qKq\n/jRkPVqxfpLFi6vKgDcgA54kSVJjHAQpSZLUGAOeJElSYwx4E5Zk/6Fr0Mrz/s1f3rv5zfs3f3nv\nhmHAmzz/oM9v3r/5y3s3v3n/5i/v3QAMeJIkSY1Z8LNob5W1am3Wndj7Xce1rMlaE3s/rVrev/nL\neze/ef/mr0nfuy22aXslndPPuvbyqtpwRdct+IWO12ZddsruQ5chSZJWgWOPPXPoEsZq9Y3Pu3Am\n19lFK0mS1BgDniRJUmMMeJIkSY0x4EmSJDXGgCdJktQYA54kSVJjDHiSJEmNMeBJkiQ1xoAnSZLU\nGAOeJElSYwx4kiRJjTHgSZIkNcaAJ0mS1BgDniRJUmMMeJIkSY0x4EmSJDXGgCdJktQYA54kSVJj\nDHiSJEmNMeBJkiQ1xoAnSZLUmJUKeElWS3JEkt8nqSQXJPnyqigoyWOS/DzJ9Uk+tCpeU5IkaSFZ\nYyWftxfwLGA34JfANUBWUU3/DXwAeA+wZBW9piRJ0oKxsgHvnsBvq+q7M7k4ya2q6i8zuG4D4PbA\nsVX1m5WsTZIkaUGbdRdt3236LmCTke7ZD4120SY5IclhSQ5JchlwSn98/SRHJrk0yVVJTkyyQ39u\nN+CK/iWO6197t/7c45P8OMm1SX6d5LVJ0p+7V5Krkzxj5P33TPKXJDuvzL8USZKk+WxlxuC9BHgz\ncBGwMfCAZVy3L1237UOAp/eB7CvAXYBHAfcDTqILcxsD3wW26p/7j/1rfzfJ9sCngc8B9wX+FXgN\n8EKAqjoHeBnwniT3SLIh8CHgwKo6dSU+nyRJ0rw26y7aqroyyVXADVV1CUDfmDbV+VX1iqUPkjwc\n2A7YsKqu6Q+/Lsmjgf2q6m1JLu2P/2HktV8OnFhVb+jPnZtkc+Bf6MbpUVVHJnkk8HHg98AvgP9c\n1mdIsj+wP8DarDPbfwWSJElz2jiXSTl9yuPtgXWAy5IsWfoDbA1stpzX2ZK+i3fEycBdkiwaOfYc\nurGBuwL7VtUNy3rBqjqyqnaoqh3WZK0ZfhxJkqT5YWUnWczE1VMerwb8jq7LdqrFK/keNfL71sD6\n/e93Ac5fydeUJEma18YZ8KY6A9gIuLGqfjmL550N7DLl2IOBi6rqKvjr7NuPAIcAtwY+kmTbqlrZ\n4ChJkjRvTXIni2/RdbV+Ickjk2yaZOckb0oyXaveUu8AHprkjUm2SLIP8ArgbSPXHA5cBryebmze\nVcD7xvMxJEmS5raJBbyqKroFko8D3g+cA3wKuBdw8XKedwbwRLqZtT8B3tr/vBcgyX7A3sA+VXVd\nVV0LPA14QpKnjO0DSZIkzVHpctfCtSi3q52y+9BlSJKkVeDYi88cuoSxWn3j806vqh1WdN0ku2gl\nSZI0AQY8SZKkxhjwJEmSGmPAkyRJaowBT5IkqTEGPEmSpMYY8CRJkhpjwJMkSWqMAU+SJKkxBjxJ\nkqTGGPAkSZIaY8CTJElqjAFPkiSpMQY8SZKkxhjwJEmSGmPAkyRJaowBT5IkqTEGPEmSpMYY8CRJ\nkhpjwJMkSWrMGkMXIEnSXPOxX58ydAljs88mDx66hLHa467bD13CmJ03o6tswZMkSWqMAU+SJKkx\nBjxJkqTGGPAkSZIaY8CTJElqjAFPkiSpMQY8SZKkxhjwJEmSGmPAkyRJaowBT5IkqTEGPEmSpMYY\n8CRJkhpjwJMkSWqMAU+SJKkxBjxJkqTGGPAkSZIaY8CTJElqjAFPkiSpMQY8SZKkxhjwJEmSGmPA\nkyRJaowBT5IkqTEGPEmSpMY0EfCSnJDkvUPXIUmSNBc0EfAkSZJ0kzkf8JKsOXQNkiRJ88msA16S\nXZN8L8mSJFcm+UGSrftzD0pyYpI/JflNksOSLBp57p5JvpPkiiR/SHJski1Hzt89SSV5apLjklwD\nPK8/98D+2NX9+x6X5M6jnyXJW5JcnuTSJIckmfMBVpIkaVWbVQBKsgbwBeBkYFtgJ+DdwA1J7gt8\nA/hif+7xwHbAUSMvsW5//Y7AbsCVwJeS3GrKWx0E/BdwH+DzSbYFjgfOA3YBHggcA6wx8px9gOuB\nBwEvBF4KPHk2n0+SJKkFa6z4kptZBGwAfKmqftEf+1+AJEcDx1TVO5ZenOQFwA+T3LGqLq2qz46+\nWJJnAYvpAt/JI6feU1WfGbnuYODMqtp/5Jqzp9T2s6p6ff/7uUmeC+wOfGLqh0iyP7A/wNqsM7NP\nLkmSNE/MqgWvqv4AfAg4NslXkrw8ySb96e2Bffuu2yVJlgCn9Oc2A0iyWZKPJ/lFksXA7/oaNrn5\nO3HalMf3A45bQXlnTXl8MXDHZXyOI6tqh6raYU3WWsHLSpIkzS+zbcGjqp6V5N3AnsDewIFJHksX\n1D4AvGuap/2m/+eXgYvoxtX9hq5L9WfA1C7aq2dbF3Dd1FKZB5NIJEmSVrVZBzyAqvoR8CPg4CRf\nA54BnAFsVVXnTfecJLcH7g38c1Ud3x+7/wxr+CHw8JWpVZIkaaGZ7SSLTZO8tZ8t+3dJHgZsQ9cK\ndzCwY5LDk9wvyT2TPCrJEf3TrwAuB57bn3socDhdK96KvB24X5Ijk2yb5F5JnjPSPSxJkqTebLsw\n/wRsAXwaOBf4MPAx4OCqOgvYFbg7cCJdC99BdOPsqKob6Wa1bgP8BHgf8Drg2hW9aVWdCfw9XQvg\n94DvA0/hlt2ykiRJC96sumir6nd0y58s6/xpdGPzlnX+OGDrKYfXGzl/AZBlPPdkugA53bndpjn2\nzGXVIUmS1DInIUiSJDXGgCdJktQYA54kSVJjDHiSJEmNMeBJkiQ1xoAnSZLUGAOeJElSYwx4kiRJ\njTHgSZIkNcaAJ0mS1BgDniRJUmMMeJIkSY0x4EmSJDXGgCdJktQYA54kSVJjDHiSJEmNMeBJkiQ1\nxoAnSZLUGAOeJElSYwx4kiRJjVlj6AIkqUmrrT50BeN14w1DVzBW+9xtl6FLGJ8MXcB4Xbb/jkOX\nMF6HHTOjy2zBkyRJaowBT5IkqTEGPEmSpMYY8CRJkhpjwJMkSWqMAU+SJKkxBjxJkqTGGPAkSZIa\nY8CTJElqjAFPkiSpMQY8SZKkxhjwJEmSGmPAkyRJaowBT5IkqTEGPEmSpMYY8CRJkhpjwJMkSWqM\nAU+SJKkxBjxJkqTGGPAkSZIaY8CTJElqjAFPkiSpMfMm4CV5ZZILhq5DkiRprps3AU+SJEkzs0oC\nXpJFSTZYFa81i/fcMMnak3xPSZKk+WClA16S1ZPskeTjwCXAtv3x9ZMcmeTSJFclOTHJDiPPe2aS\nJUl2T/KTJFcnOT7JplNe/9VJLumvPRpYb0oJewGX9O+1y8p+DkmSpNbMOuAl2SrJ24BfA8cAVwN7\nAiclCfAV4C7Ao4D7AScBxyXZeORl1gJeAzwb2BnYADh85D2eBPwn8Abg/sA5wMunlPIx4GnAbYBv\nJjkvyeunBkVJkqSFZkYBL8ntk7w4yenAD4F7Ay8B7lRVz62qk6qqgIcB2wFPqKofVNV5VfU64JfA\nfiMvuQZwQH/NWcAhwG59QAR4KfDhqjqiqs6tqgOBH4zWVFXXV9VXq+qpwJ2At/Tv//MkJyR5dpKp\nrX6SJEnNm2kL3ouAQ4E/A1tU1d5V9emq+vOU67YH1gEu67tWlyRZAmwNbDZy3bVVdc7I44uBWwG3\n7R9vCZw65bWnPv6rqlpcVUdV1cOABwAbAf8NPGG665Psn+S0JKddx7XL+diSJEnzzxozvO5I4Drg\n6cBPkvw/4CPAt6vqhpHrVgN+BzxkmtdYPPL79VPO1cjzZy3JWnRdwvvSjc37KV0r4Bemu76qjqT7\nTCzK7Wq6ayRJkuarGQWqqrq4qg6sqnsBfw8sAT4JXJTkHUm26y89g6717Ma+e3b059JZ1HU28MAp\nx272OJ0HJzmCbpLHe4DzgO2r6v5VdWhVXTGL95QkSWrCrFvMqup7VfUCYGO6rtstgP9J8hDgW8Ap\nwBeSPDLJpkl2TvKm/vxMHQo8I8lzk2ye5DXATlOu2Rf4BrAIeCpwt6p6VVX9ZLafSZIkqSUz7aK9\nhaq6FvgM8JkkdwRuqKpKshfdDNj3A3ek67I9BTh6Fq99TJJ7AAfSjen7IvBO4Jkjl32bbpLH4lu+\ngiRJ0sKVbvLrwrUot6udsvvQZUhqzWqrD13BeN14w4qv0dz01wUr2nTZ86aO8GrLjw57xelVtcOK\nrnOrMkmSpMYY8CRJkhpjwJMkSWqMAU+SJKkxBjxJkqTGGPAkSZIaY8CTJElqjAFPkiSpMQY8SZKk\nxhjwJEmSGmPAkyRJaowBT5IkqTEGPEmSpMYY8CRJkhpjwJMkSWqMAU+SJKkxBjxJkqTGGPAkSZIa\nY8CTJElqjAFPkiSpMQY8SZKkxqwxdAGS1KQbbxi6Aml6VUNXMFYbHn7q0CXMCbbgSZIkNcaAJ0mS\n1BgDniRJUmMMeJIkSY0x4EmSJDXGgCdJktQYA54kSVJjDHiSJEmNMeBJkiQ1xoAnSZLUGAOeJElS\nYwx4kiRJjTHgSZIkNcaAJ0mS1BgDniRJUmMMeJIkSY0x4EmSJDXGgCdJktQYA54kSVJjDHiSJEmN\nMeBJkiQ1xoAnSZLUGAOeJElSYwx4kiRJjTHgSZIkNcaAJ0mS1BgDniRJUmPWGLqAISTZH9gfYG3W\nGbgaSZKkVWtBtuBV1ZFVtUNV7bAmaw1djiRJ0iq1IAOeJElSywx4kiRJjTHgSZIkNcaAJ0mS1BgD\nniRJUmMMeJIkSY0x4EmSJDXGgCdJktQYA54kSVJjDHiSJEmNMeBJkiQ1xoAnSZLUGAOeJElSYwx4\nkiRJjTHgSZIkNcaAJ0mS1BgDniRJUmMMeJIkSY0x4EmSJDXGgCdJktQYA54kSVJjDHiSJEmNMeBJ\nkiQ1xoAnSZLUGAOeJElSYwx4kiRJjUlVDV3DoJJcBlw4wbe8A3D5BN9Pq5b3b/7y3s1v3r/5y3u3\nav1dVW24oosWfMCbtCSnVdUOQ9ehleP9m7+8d/Ob92/+8t4Nwy5aSZKkxhjwJEmSGmPAm7wjhy5A\nfxPv3/zlvZvfvH/zl/duAI7BkyRJaowteJIkSY0x4EmSJDXGgCdJktQYA54kSVJjDHiSJEmN+f+q\nn6JaMzwYOwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAMO3g6g4N7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68419868-d9da-4eb2-c4da-58e5368001d0"
      },
      "source": [
        "  from tensorflow.python.util import compat\n",
        "  #where to save to?\n",
        "  export_path_base = 'model'\n",
        "  export_path = os.path.join(\n",
        "      compat.as_bytes(export_path_base))\n",
        "  print ('Exporting trained model to', export_path)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exporting trained model to b'model'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPUn8Eyc0ffQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "176756c9-3639-42d5-fe1b-e54069658c45"
      },
      "source": [
        "from tensorflow.python.saved_model import builder as saved_model_builder\n",
        "from tensorflow.python.saved_model import signature_constants\n",
        "from tensorflow.python.saved_model import signature_def_utils\n",
        "from tensorflow.python.saved_model import tag_constants\n",
        "from tensorflow.python.saved_model import utils\n",
        "  \n",
        "  #This creates a SERVABLE from our model\n",
        "  #saves a \"snapshot\" of the trained model to reliable storage \n",
        "  #so that it can be loaded later for inference.\n",
        "  #can save as many version as necessary\n",
        "  \n",
        "  #the tensoroflow serving main file tensorflow_model_server\n",
        "  #will create a SOURCE out of it, the source\n",
        "  #can house state that is shared across multiple servables \n",
        "  #or versions\n",
        "  \n",
        "  #we can later create a LOADER from it using tf.saved_model.loader.load\n",
        "  \n",
        "  #then the MANAGER decides how to handle its lifecycle\n",
        "  \n",
        "builder = saved_model_builder.SavedModelBuilder(export_path)\n",
        "\n",
        "  # Build the signature_def_map.\n",
        "  #Signature specifies what type of model is being exported, \n",
        "  #and the input/output tensors to bind to when running inference.\n",
        "  #think of them as annotiations on the graph for serving\n",
        "  #we can use them a number of ways\n",
        "  #grabbing whatever inputs/outputs/models we want either on server\n",
        "  #or via client\n",
        "classification_inputs = utils.build_tensor_info(serialized_tf_example)\n",
        "classification_outputs_classes = utils.build_tensor_info(prediction_classes)\n",
        "classification_outputs_scores = utils.build_tensor_info(values)\n",
        "\n",
        "   \n",
        "classification_signature = signature_def_utils.build_signature_def(\n",
        "    inputs={signature_constants.CLASSIFY_INPUTS: classification_inputs},\n",
        "    outputs={\n",
        "        signature_constants.CLASSIFY_OUTPUT_CLASSES:\n",
        "            classification_outputs_classes,\n",
        "        signature_constants.CLASSIFY_OUTPUT_SCORES:\n",
        "            classification_outputs_scores\n",
        "    },\n",
        "    method_name=signature_constants.CLASSIFY_METHOD_NAME)\n",
        "\n",
        "tensor_info_x = utils.build_tensor_info(x)\n",
        "tensor_info_y = utils.build_tensor_info(y)\n",
        "\n",
        "prediction_signature = signature_def_utils.build_signature_def(\n",
        "    inputs={'images': tensor_info_x},\n",
        "    outputs={'scores': tensor_info_y},\n",
        "    method_name=signature_constants.PREDICT_METHOD_NAME)\n",
        "legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
        "  \n",
        "  #add the sigs to the servable\n",
        "builder.add_meta_graph_and_variables(\n",
        "    sess, [tag_constants.SERVING],\n",
        "    signature_def_map={\n",
        "        'predict_images':\n",
        "            prediction_signature,\n",
        "        signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
        "            classification_signature,\n",
        "    },\n",
        "    legacy_init_op=legacy_init_op)\n",
        " #save it!\n",
        "builder.save()\n",
        "\n",
        "print ('Done exporting!')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-ea37a03b56aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;31m#grabbing whatever inputs/outputs/models we want either on server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;31m#or via client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mclassification_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tensor_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_tf_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mclassification_outputs_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tensor_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mclassification_outputs_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tensor_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'serialized_tf_example' is not defined"
          ]
        }
      ]
    }
  ]
}